{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulta do Usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConsultaUsuário(consulta):\n",
    "    \n",
    "    My_stopwords = set(stopwords.words('english'))\n",
    "    \n",
    "    # Separar a consulta por palavras.\n",
    "    palavras = word_tokenize(consulta)\n",
    "    \n",
    "    # Remover as Stopwords.\n",
    "    lista_Termos = [i for i in palavras if i not in My_stopwords]\n",
    "    lista_Termos = list(dict.fromkeys(lista_Termos))\n",
    "    \n",
    "    # Stemming para pegar termos similares atraves dos radicais das palavras.\n",
    "    ps = PorterStemmer()\n",
    "    lista_radicais = []\n",
    "    for w in lista_Termos:\n",
    "        if ps.stem(w) not in lista_radicais: \n",
    "            lista_radicais.append(ps.stem(w))\n",
    "\n",
    "    return lista_Termos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indice Invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = r'Black Lotus is the most expensive card of the game!'\n",
    "doc2 = r'The price of Black dragon card is $12,00!'\n",
    "doc3 = r'Testing the test of a testment of tests'\n",
    "Documentos = [doc1 ,doc2,doc3]\n",
    "\n",
    "def IndiceInvertido(listaDoc):\n",
    "    My_stopwords = set(stopwords.words('english'))\n",
    "    postings = []\n",
    "    #termosPostings = []\n",
    "    for doc in listaDoc:\n",
    "        # termos do doc\n",
    "        termos = word_tokenize(doc)\n",
    "        # Remover as Stopwords.\n",
    "        lista_Termos = [i for i in termos if i not in My_stopwords]\n",
    "        for termo in lista_Termos:\n",
    "        #if termo not in termosPostings:\n",
    "        #    termosPostings.append(termo)\n",
    "        \n",
    "            postings.append((termo,doc))    \n",
    "    return postings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ler Postings - Document at Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Document_at_Time(documento,consulta):\n",
    "    count = 0\n",
    "    \n",
    "    #Lista com os termos iguais (termo, documento)\n",
    "    termosIguais = []\n",
    "    \n",
    "    # lista de Nomes dos documentos para cada termo igual ao da consulta.(doc1,doc1,doc2,doc1,dco4...)\n",
    "    Documents = []\n",
    "    \n",
    "    for termo in termosConsulta:\n",
    "        for postingTermo in Postings:\n",
    "            if termo == postingTermo[0]:\n",
    "                termosIguais.append((termo,postingTermo[1]))\n",
    "                Documents.append(postingTermo[1])\n",
    "    \n",
    "    # Contando a frequencia de docmentos que possuem termos da consulta(quantsos termos da consulta o doc tem?)\n",
    "    scoreDocumentos = Counter(Documents)\n",
    "    #dicionario com doc:frequencia\n",
    "    scoreDocumentos = dict(scoreDocumentos)    \n",
    "    \n",
    "    #nomes dos documentos sem duplicatas\n",
    "    documentosNomes = list(scoreDocumentos) \n",
    "    dataScore = []\n",
    "    \n",
    "    for doc in documentosNomes:\n",
    "        frequencia = scoreDocumentos[doc]\n",
    "        dataScore.append(dict(zip(['Documento','Score/Frequencia'],[doc,frequencia])))\n",
    "    \n",
    "    return pd.DataFrame(dataScore,columns=['Documento','Score/Frequencia'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplos de Teste\n",
    "* Modelo do Indice Invertido [ Termo , [ ( DOCUMENTO , TF/IDF ) ] ]\n",
    "* Modelo da Consulta do Usuário: Texto qualquer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Docs = [\n",
    "    ['Black',[('doc1',1),('doc2',2)]],\n",
    "    ['dragon',[('doc2',3),('doc3',1)]],\n",
    "    ['Illusion',[('doc4',1)]]\n",
    "]\n",
    "\n",
    "consulta = r'Black Lotus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Espaço Vetorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade Cosseno de Vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similaridade Cosseno\n",
    "def SimilaridadeCosseno(vetorQuery,vetorDoc):\n",
    "    score = np.dot(vetorQuery,vetorDoc) / (math.sqrt((np.dot(vetorQuery,vetorQuery))*(np.dot(vetorDoc,vetorDoc))))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix de Vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>doc4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lotus</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dragon</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illusion</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Query  doc1  doc2  doc3  doc4\n",
       "Black         1     1     1     0     0\n",
       "Lotus         1     0     0     0     0\n",
       "dragon        0     0     1     1     0\n",
       "Illusion      0     0     0     0     1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MatrixVetores(Postings,query):\n",
    "    \n",
    "    # Lista com os termos tanto dos postings quanto da consulta.\n",
    "    termosVocabulario = []\n",
    "    \n",
    "    # Add consulta(query) e os documentos.\n",
    "    documentoNomes = [query]\n",
    "    \n",
    "    # Add termos da consulta ao vocabulario.\n",
    "    for termos in ConsultaUsuário(query):\n",
    "        if termos not in termosVocabulario:\n",
    "            termosVocabulario.append(termos)\n",
    "    \n",
    "    # Add os termos dos documentos dos postings ao vocabulario.\n",
    "    for posting in Postings:\n",
    "        if posting[0] not in termosVocabulario:\n",
    "            termosVocabulario.append(posting[0])\n",
    "        for tupla in posting[1]:\n",
    "            if tupla[0] not in documentoNomes:\n",
    "                documentoNomes.append(tupla[0])\n",
    "    \n",
    "    #print('termos do Vocabulario (Query e Documentos): ',termosVocabulario,\"\\n\\n\")\n",
    "    #print('Nome dos Documentos (Query e Documentos): ',documentoNomes,\"\\n\\n\")\n",
    "    \n",
    "    # Criando matrix de vetores \n",
    "    matrixVazia = np.empty((len(termosVocabulario),len(documentoNomes)),dtype=object)\n",
    "    \n",
    "    # Add nomes as rows e columns (rows = termos e columns docs)\n",
    "    df = pd.DataFrame(matrixVazia, columns=documentoNomes, index=termosVocabulario)\n",
    "    \n",
    "    # Inserir os valores na matrix (sem tf/idf) se existe 1 se não 0\n",
    "    nameColumns = list(df.columns)\n",
    "    nameRows = list(df.index)\n",
    "     \n",
    "    # Preenchendo os valores dos vetores usando Document-at-time.\n",
    "    for doc in nameColumns:\n",
    "        for termo in nameRows:\n",
    "            \n",
    "            # Verificando a query.\n",
    "            if termo in ConsultaUsuário(query) and doc == query:\n",
    "                df.loc[termo,doc] = 1\n",
    "            else:\n",
    "                df.loc[termo,doc] = 0\n",
    "     \n",
    "            # Verificando os docs.\n",
    "            for posting in Postings:\n",
    "                if termo == posting[0]:\n",
    "                    for tupla in posting[1]:\n",
    "                        if doc == tupla[0]:\n",
    "                            if tupla[1] > 0:\n",
    "                                df.loc[termo,doc] = 1\n",
    "                            else:\n",
    "                                df.loc[termo,doc] = 0\n",
    "      \n",
    "    \n",
    "    df.rename(columns={query:'Query'},inplace = True)    \n",
    "    #display(df)\n",
    "    return df\n",
    "MatrixVetores(Docs,consulta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respota Consulta \n",
    "    *Lista de Documentos Ordenada pela similaridade dos cossenos (Documento e Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta\n",
    "def RespostaConsulta(matrixVetores):\n",
    "    \n",
    "    # Lista de cocumentos e seus scores (doc,score)\n",
    "    ListaDocumentos = []\n",
    "    \n",
    "    # Pegando o vetorQuery\n",
    "    vetorQuery = matrixVetores['Query'].to_numpy()\n",
    "    \n",
    "    for col in matrixVetores.columns:  \n",
    "        # Score da Similaridade de cossenos\n",
    "        score = SimilaridadeCosseno(vetorQuery,matrixVetores[col].to_numpy())\n",
    "        \n",
    "        # documento comparado a query\n",
    "        documento = col\n",
    "\n",
    "        ListaDocumentos.append((documento,score))\n",
    "    \n",
    "    # Ordenar pelo Score.\n",
    "    ListaDocumentos.sort(key=operator.itemgetter(1),reverse=True)\n",
    "    \n",
    "    return ListaDocumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Query', 1.0),\n",
       " ('doc1', 0.7071067811865475),\n",
       " ('doc2', 0.5),\n",
       " ('doc3', 0.0),\n",
       " ('doc4', 0.0)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RespostaConsulta(MatrixVetores(Docs,consulta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlação de Spearman\n",
    "def Correlação_Spearman():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
